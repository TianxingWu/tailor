{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d47e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b24d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_as_dataframe(list_of_namedtuples, keys=None):\n",
    "    if isinstance(list_of_namedtuples[0], list):\n",
    "        if not keys:\n",
    "            keys = range(len(list_of_namedtuples))\n",
    "        return pd.concat([pd.DataFrame(tup_list) for tup_list in list_of_namedtuples], keys=keys)\n",
    "    return pd.DataFrame(list_of_namedtuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "981bbb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/Users/akshitab/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2817de0363694366ae410b6be3827719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snli = datasets.load_dataset(\"snli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d6a8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_to_perturb = \"hypothesis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025cbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dict = snli[\"train\"][:5]\n",
    "sentences = data_dict[key_to_perturb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa32ded2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A person is training his horse for a competition.',\n",
       " 'A person is at a diner, ordering an omelette.',\n",
       " 'A person is outdoors, on a horse.',\n",
       " 'They are smiling at their parents',\n",
       " 'There are children present']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a5303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.steps.process_with_spacy import GetSpacyModel, ProcessWithSpacy\n",
    "from tailor.steps.get_srl_tags import GetSRLTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9f5e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = GetSpacyModel().run(parse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c32193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_outputs = ProcessWithSpacy().run(sentences=sentences, spacy_model=spacy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79f207e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[A person is training his horse for a competition.,\n",
       " A person is at a diner, ordering an omelette.,\n",
       " A person is outdoors, on a horse.,\n",
       " They are smiling at their parents,\n",
       " There are children present]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56f5ddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 00:32:33,768 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-02-03 00:32:33,775 - INFO - allennlp.models.archival - loading archive file /Users/akshitab/.cache/cached_path/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "2022-02-03 00:32:33,776 - INFO - allennlp.models.archival - extracting archive file /Users/akshitab/.cache/cached_path/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /var/folders/hj/vgtd6j153yq38z5xtrvrmpqr0000gn/T/tmpr3dz840h\n",
      "2022-02-03 00:32:37,413 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-02-03 00:32:37,415 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-02-03 00:32:37,415 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-02-03 00:32:37,416 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-02-03 00:32:37,417 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-02-03 00:32:37,417 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-02-03 00:32:37,418 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2022-02-03 00:32:58,745 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-02-03 00:32:58,746 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-02-03 00:32:58,747 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-02-03 00:32:58,747 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-02-03 00:32:58,748 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-02-03 00:32:58,748 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-02-03 00:32:58,749 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2022-02-03 00:33:05,036 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-02-03 00:33:05,036 - INFO - allennlp.data.vocabulary - Loading token dictionary from /var/folders/hj/vgtd6j153yq38z5xtrvrmpqr0000gn/T/tmpr3dz840h/vocabulary.\n",
      "2022-02-03 00:33:05,039 - INFO - allennlp.common.params - model.type = srl_bert\n",
      "2022-02-03 00:33:05,040 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-02-03 00:33:05,040 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2022-02-03 00:33:05,041 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
      "2022-02-03 00:33:05,042 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
      "2022-02-03 00:33:05,042 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fda841ef400>\n",
      "2022-02-03 00:33:05,043 - INFO - allennlp.common.params - model.label_smoothing = None\n",
      "2022-02-03 00:33:05,043 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
      "2022-02-03 00:33:05,044 - INFO - allennlp.common.params - model.srl_eval_path = /Users/akshitab/virtuals/tailor/lib/python3.8/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "2022-02-03 00:33:09,457 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-02-03 00:33:09,459 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-02-03 00:33:09,460 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
      "2022-02-03 00:33:09,461 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
      "2022-02-03 00:33:09,461 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
      "2022-02-03 00:33:09,463 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
      "2022-02-03 00:33:09,464 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
      "2022-02-03 00:33:09,464 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,465 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,466 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,467 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-02-03 00:33:09,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-02-03 00:33:09,468 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-02-03 00:33:09,469 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-02-03 00:33:09,469 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-02-03 00:33:09,470 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-02-03 00:33:09,470 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,471 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,472 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,472 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,473 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
      "2022-02-03 00:33:09,474 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
      "2022-02-03 00:33:09,474 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,475 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,475 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,476 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,476 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-02-03 00:33:09,477 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-02-03 00:33:09,478 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-02-03 00:33:09,479 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-02-03 00:33:09,480 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-02-03 00:33:09,480 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-02-03 00:33:09,481 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,482 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,483 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,483 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,484 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
      "2022-02-03 00:33:09,485 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
      "2022-02-03 00:33:09,486 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,486 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,487 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,488 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 00:33:09,488 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-02-03 00:33:09,489 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-02-03 00:33:09,489 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-02-03 00:33:09,490 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-02-03 00:33:09,491 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-02-03 00:33:09,491 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-02-03 00:33:09,492 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,492 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,493 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,494 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,494 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
      "2022-02-03 00:33:09,495 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
      "2022-02-03 00:33:09,495 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,496 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,497 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,498 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,499 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-02-03 00:33:09,499 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-02-03 00:33:09,500 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-02-03 00:33:09,501 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-02-03 00:33:09,502 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-02-03 00:33:09,502 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-02-03 00:33:09,503 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,504 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,505 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,506 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,506 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
      "2022-02-03 00:33:09,507 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
      "2022-02-03 00:33:09,507 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,508 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,509 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,509 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,510 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-02-03 00:33:09,510 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-02-03 00:33:09,511 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-02-03 00:33:09,512 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-02-03 00:33:09,512 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-02-03 00:33:09,513 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-02-03 00:33:09,513 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,514 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,515 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,516 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,517 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
      "2022-02-03 00:33:09,517 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
      "2022-02-03 00:33:09,518 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,520 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,521 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-02-03 00:33:09,522 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-02-03 00:33:09,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-02-03 00:33:09,523 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-02-03 00:33:09,524 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-02-03 00:33:09,525 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-02-03 00:33:09,526 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,526 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,526 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,527 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,528 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
      "2022-02-03 00:33:09,528 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
      "2022-02-03 00:33:09,529 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,529 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,530 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,531 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,532 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-02-03 00:33:09,533 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-02-03 00:33:09,534 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-02-03 00:33:09,534 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-02-03 00:33:09,535 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-02-03 00:33:09,536 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-02-03 00:33:09,537 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 00:33:09,538 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,538 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,539 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,540 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
      "2022-02-03 00:33:09,540 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
      "2022-02-03 00:33:09,541 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,541 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,542 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,543 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,543 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-02-03 00:33:09,544 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-02-03 00:33:09,544 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-02-03 00:33:09,545 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-02-03 00:33:09,545 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-02-03 00:33:09,546 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-02-03 00:33:09,546 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,547 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,548 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,548 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,548 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
      "2022-02-03 00:33:09,549 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
      "2022-02-03 00:33:09,550 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,551 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,551 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,552 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,553 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-02-03 00:33:09,554 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-02-03 00:33:09,555 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-02-03 00:33:09,556 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-02-03 00:33:09,556 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-02-03 00:33:09,557 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-02-03 00:33:09,557 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,558 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,558 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,559 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,560 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
      "2022-02-03 00:33:09,560 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
      "2022-02-03 00:33:09,561 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,561 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,562 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,562 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,563 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-02-03 00:33:09,564 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-02-03 00:33:09,565 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-02-03 00:33:09,566 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-02-03 00:33:09,567 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-02-03 00:33:09,567 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-02-03 00:33:09,568 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,569 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,570 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,571 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,571 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
      "2022-02-03 00:33:09,572 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
      "2022-02-03 00:33:09,573 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,573 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,574 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,575 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,575 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-02-03 00:33:09,576 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-02-03 00:33:09,577 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-02-03 00:33:09,577 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-02-03 00:33:09,578 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-02-03 00:33:09,578 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-02-03 00:33:09,579 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,579 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,580 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,581 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,581 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
      "2022-02-03 00:33:09,582 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
      "2022-02-03 00:33:09,582 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,583 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-03 00:33:09,583 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-02-03 00:33:09,584 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-02-03 00:33:09,584 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-02-03 00:33:09,585 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-02-03 00:33:09,586 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-02-03 00:33:09,586 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-02-03 00:33:09,587 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-02-03 00:33:09,587 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-02-03 00:33:09,588 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-02-03 00:33:09,589 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-02-03 00:33:09,589 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-02-03 00:33:09,590 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-02-03 00:33:09,590 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
      "2022-02-03 00:33:09,591 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
      "2022-02-03 00:33:09,592 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
      "2022-02-03 00:33:09,593 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
      "2022-02-03 00:33:09,594 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
      "2022-02-03 00:33:09,595 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
      "2022-02-03 00:33:10,008 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /var/folders/hj/vgtd6j153yq38z5xtrvrmpqr0000gn/T/tmpr3dz840h\n"
     ]
    }
   ],
   "source": [
    "processed_sentences = GetSRLTags().run(spacy_outputs=spacy_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc28560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>spacy_doc</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person is training his horse for a competiti...</td>\n",
       "      <td>(A, person, is, training, his, horse, for, a, ...</td>\n",
       "      <td>[{'verb': 'is', 'description': 'A person [V: i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person is at a diner , ordering an omelette .</td>\n",
       "      <td>(A, person, is, at, a, diner, ,, ordering, an,...</td>\n",
       "      <td>[{'verb': 'is', 'description': '[ARG1: A perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person is outdoors , on a horse .</td>\n",
       "      <td>(A, person, is, outdoors, ,, on, a, horse, .)</td>\n",
       "      <td>[{'verb': 'is', 'description': '[ARG1: A perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>(They, are, smiling, at, their, parents)</td>\n",
       "      <td>[{'verb': 'are', 'description': 'They [V: are]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are children present</td>\n",
       "      <td>(There, are, children, present)</td>\n",
       "      <td>[{'verb': 'are', 'description': 'There [V: are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  A person is training his horse for a competiti...   \n",
       "1    A person is at a diner , ordering an omelette .   \n",
       "2                A person is outdoors , on a horse .   \n",
       "3                  They are smiling at their parents   \n",
       "4                         There are children present   \n",
       "\n",
       "                                           spacy_doc  \\\n",
       "0  (A, person, is, training, his, horse, for, a, ...   \n",
       "1  (A, person, is, at, a, diner, ,, ordering, an,...   \n",
       "2      (A, person, is, outdoors, ,, on, a, horse, .)   \n",
       "3           (They, are, smiling, at, their, parents)   \n",
       "4                    (There, are, children, present)   \n",
       "\n",
       "                                               verbs  \n",
       "0  [{'verb': 'is', 'description': 'A person [V: i...  \n",
       "1  [{'verb': 'is', 'description': '[ARG1: A perso...  \n",
       "2  [{'verb': 'is', 'description': '[ARG1: A perso...  \n",
       "3  [{'verb': 'are', 'description': 'They [V: are]...  \n",
       "4  [{'verb': 'are', 'description': 'There [V: are...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_as_dataframe(processed_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb55120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.common.perturb_function import ChangeVoice, SwapCoreWithContext, SwapCoreWithoutContext, ShortenCoreArgument, ChangeTense\n",
    "from tailor.steps.perturb_prompt import PerturbPromptWithString, PerturbPromptWithFunction\n",
    "from tailor.steps.combine_all_prompts import CombineAllPrompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b15d0d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning. Perturbed prompt is same as base prompt. This should not be happening.\n"
     ]
    }
   ],
   "source": [
    "sentence_prompts = []\n",
    "perturbs = {\n",
    "    ChangeVoice: \"preserves_meaning\",\n",
    "    ShortenCoreArgument: \"preserves_meaning\",\n",
    "    SwapCoreWithContext: \"changes_meaning\",\n",
    "    SwapCoreWithoutContext: \"changes_meaning\",\n",
    "    ChangeTense: \"preserves_meaning\"\n",
    "}\n",
    "for perturb_fn in [ChangeVoice, SwapCoreWithContext, SwapCoreWithoutContext, ShortenCoreArgument, ChangeTense]:\n",
    "    perturbations = PerturbPromptWithString().run(processed_sentences=processed_sentences, perturb_str_func=perturb_fn(), description=perturbs[perturb_fn])\n",
    "    sentence_prompts.append(perturbations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f226a5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.tasks.nli.perturbations import ReplaceCoreWithSubsequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ac9232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_core_with_subs = PerturbPromptWithFunction().run(processed_sentences=processed_sentences, perturb_fn=ReplaceCoreWithSubsequence(), description=\"changes_meaning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f4999b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_prompts.append(replace_core_with_subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e58b085",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_prompts = CombineAllPrompts().run(sentence_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "440d051d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>meta</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>[VERB+passive+present: be]  &lt;extra_id_0&gt; &lt;extr...</td>\n",
       "      <td>A person [VERB: is] training his horse for a c...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [], 'blank_i...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VERB+passive+present: train | AGENT+complete:...</td>\n",
       "      <td>[AGENT: A person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'his horse', 'tle...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[VERB+active+present: train | AGENT+complete: ...</td>\n",
       "      <td>[PATIENT: A person] is [VERB: training] [GOAL:...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'his horse', 'tle...</td>\n",
       "      <td>swap_core_with_context</td>\n",
       "      <td>changes_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[VERB+active+present: train | AGENT+complete: ...</td>\n",
       "      <td>[PATIENT: A person] is [VERB: training] [GOAL:...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'his horse', 'tle...</td>\n",
       "      <td>swap_core_without_context</td>\n",
       "      <td>changes_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[VERB+active+present: train | AGENT+complete: ...</td>\n",
       "      <td>[AGENT: A person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[VERB+active+present: train | AGENT+complete: ...</td>\n",
       "      <td>[AGENT: A person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[VERB+active+future: be | MODAL: *] A person &lt;...</td>\n",
       "      <td>A person [VERB: is] training his horse for a c...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': '*', 'tlemma_type...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[VERB+active+future: train | AGENT+complete: a...</td>\n",
       "      <td>[AGENT: A person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'his horse', 'tle...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[VERB+active+present: train | AGENT+complete: ...</td>\n",
       "      <td>[AGENT: A person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>replace_core_with_subsequence</td>\n",
       "      <td>changes_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">1</th>\n",
       "      <th>0</th>\n",
       "      <td>[VERB+passive+present: be | PATIENT+complete: ...</td>\n",
       "      <td>[PATIENT: A person] [VERB: is] [PREDICATE: at ...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'at a diner', 'tl...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VERB+passive+present: order | AGENT+complete:...</td>\n",
       "      <td>[AGENT: A person] is at a diner, [VERB: orderi...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[VERB+active+present: order | AGENT+complete: ...</td>\n",
       "      <td>[PATIENT: A person] is at a diner, [VERB: orde...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>swap_core_with_context</td>\n",
       "      <td>changes_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[VERB+active+present: order | AGENT+complete: ...</td>\n",
       "      <td>[PATIENT: A person] is at a diner, [VERB: orde...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>swap_core_without_context</td>\n",
       "      <td>changes_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[VERB+active+present: order | AGENT+complete: ...</td>\n",
       "      <td>[AGENT: A person] is at a diner, [VERB: orderi...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[VERB+active+future: be | PATIENT+complete: a ...</td>\n",
       "      <td>[PATIENT: A person] [VERB: is] [PREDICATE: at ...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'at a diner', 'tl...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[VERB+active+future: order | AGENT+complete: a...</td>\n",
       "      <td>[AGENT: A person] is at a diner, [VERB: orderi...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': '*', 'tlemma_type...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>0</th>\n",
       "      <td>[VERB+passive+present: be | PATIENT+complete: ...</td>\n",
       "      <td>[PATIENT: A person] [VERB: is] [PREDICATE: out...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'outdoors', 'tlem...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VERB+active+future: be | PATIENT+complete: a ...</td>\n",
       "      <td>[PATIENT: A person] [VERB: is] [PREDICATE: out...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'outdoors', 'tlem...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">3</th>\n",
       "      <th>0</th>\n",
       "      <td>[VERB+passive+present: be]  &lt;extra_id_0&gt; &lt;extr...</td>\n",
       "      <td>They [VERB: are] smiling at their parents</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [], 'blank_i...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VERB+passive+present: smile | AGENT+complete:...</td>\n",
       "      <td>[AGENT: They] are [VERB: smiling] [CAUSE: at t...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'at their parents...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[VERB+active+present: smile | AGENT+complete: ...</td>\n",
       "      <td>[AGENT: They] are [VERB: smiling] [CAUSE: at t...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[VERB+active+past: be] They &lt;extra_id_0&gt; smili...</td>\n",
       "      <td>They [VERB: are] smiling at their parents</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [], 'blank_i...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[VERB+active+past: smile | AGENT+complete: the...</td>\n",
       "      <td>[AGENT: They] are [VERB: smiling] [CAUSE: at t...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'at their parents...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>[VERB+passive+present: be | PATIENT+complete: ...</td>\n",
       "      <td>There [VERB: are] [PATIENT: children present]</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VERB+active+past: be | PATIENT+complete: chil...</td>\n",
       "      <td>There [VERB: are] [PATIENT: children present]</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>preserves_meaning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                prompt  \\\n",
       "0 0  [VERB+passive+present: be]  <extra_id_0> <extr...   \n",
       "  1  [VERB+passive+present: train | AGENT+complete:...   \n",
       "  2  [VERB+active+present: train | AGENT+complete: ...   \n",
       "  3  [VERB+active+present: train | AGENT+complete: ...   \n",
       "  4  [VERB+active+present: train | AGENT+complete: ...   \n",
       "  5  [VERB+active+present: train | AGENT+complete: ...   \n",
       "  6  [VERB+active+future: be | MODAL: *] A person <...   \n",
       "  7  [VERB+active+future: train | AGENT+complete: a...   \n",
       "  8  [VERB+active+present: train | AGENT+complete: ...   \n",
       "1 0  [VERB+passive+present: be | PATIENT+complete: ...   \n",
       "  1  [VERB+passive+present: order | AGENT+complete:...   \n",
       "  2  [VERB+active+present: order | AGENT+complete: ...   \n",
       "  3  [VERB+active+present: order | AGENT+complete: ...   \n",
       "  4  [VERB+active+present: order | AGENT+complete: ...   \n",
       "  5  [VERB+active+future: be | PATIENT+complete: a ...   \n",
       "  6  [VERB+active+future: order | AGENT+complete: a...   \n",
       "2 0  [VERB+passive+present: be | PATIENT+complete: ...   \n",
       "  1  [VERB+active+future: be | PATIENT+complete: a ...   \n",
       "3 0  [VERB+passive+present: be]  <extra_id_0> <extr...   \n",
       "  1  [VERB+passive+present: smile | AGENT+complete:...   \n",
       "  2  [VERB+active+present: smile | AGENT+complete: ...   \n",
       "  3  [VERB+active+past: be] They <extra_id_0> smili...   \n",
       "  4  [VERB+active+past: smile | AGENT+complete: the...   \n",
       "4 0  [VERB+passive+present: be | PATIENT+complete: ...   \n",
       "  1  [VERB+active+past: be | PATIENT+complete: chil...   \n",
       "\n",
       "                                                answer  \\\n",
       "0 0  A person [VERB: is] training his horse for a c...   \n",
       "  1  [AGENT: A person] is [VERB: training] [GOAL: h...   \n",
       "  2  [PATIENT: A person] is [VERB: training] [GOAL:...   \n",
       "  3  [PATIENT: A person] is [VERB: training] [GOAL:...   \n",
       "  4  [AGENT: A person] is [VERB: training] [GOAL: h...   \n",
       "  5  [AGENT: A person] is [VERB: training] [GOAL: h...   \n",
       "  6  A person [VERB: is] training his horse for a c...   \n",
       "  7  [AGENT: A person] is [VERB: training] [GOAL: h...   \n",
       "  8  [AGENT: A person] is [VERB: training] [GOAL: h...   \n",
       "1 0  [PATIENT: A person] [VERB: is] [PREDICATE: at ...   \n",
       "  1  [AGENT: A person] is at a diner, [VERB: orderi...   \n",
       "  2  [PATIENT: A person] is at a diner, [VERB: orde...   \n",
       "  3  [PATIENT: A person] is at a diner, [VERB: orde...   \n",
       "  4  [AGENT: A person] is at a diner, [VERB: orderi...   \n",
       "  5  [PATIENT: A person] [VERB: is] [PREDICATE: at ...   \n",
       "  6  [AGENT: A person] is at a diner, [VERB: orderi...   \n",
       "2 0  [PATIENT: A person] [VERB: is] [PREDICATE: out...   \n",
       "  1  [PATIENT: A person] [VERB: is] [PREDICATE: out...   \n",
       "3 0          They [VERB: are] smiling at their parents   \n",
       "  1  [AGENT: They] are [VERB: smiling] [CAUSE: at t...   \n",
       "  2  [AGENT: They] are [VERB: smiling] [CAUSE: at t...   \n",
       "  3          They [VERB: are] smiling at their parents   \n",
       "  4  [AGENT: They] are [VERB: smiling] [CAUSE: at t...   \n",
       "4 0      There [VERB: are] [PATIENT: children present]   \n",
       "  1      There [VERB: are] [PATIENT: children present]   \n",
       "\n",
       "                                                  meta  \\\n",
       "0 0  {'noncore_args': [], 'core_args': [], 'blank_i...   \n",
       "  1  {'noncore_args': [{'tlemma': 'his horse', 'tle...   \n",
       "  2  {'noncore_args': [{'tlemma': 'his horse', 'tle...   \n",
       "  3  {'noncore_args': [{'tlemma': 'his horse', 'tle...   \n",
       "  4  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "  5  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "  6  {'noncore_args': [{'tlemma': '*', 'tlemma_type...   \n",
       "  7  {'noncore_args': [{'tlemma': 'his horse', 'tle...   \n",
       "  8  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "1 0  {'noncore_args': [{'tlemma': 'at a diner', 'tl...   \n",
       "  1  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "  2  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "  3  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "  4  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "  5  {'noncore_args': [{'tlemma': 'at a diner', 'tl...   \n",
       "  6  {'noncore_args': [{'tlemma': '*', 'tlemma_type...   \n",
       "2 0  {'noncore_args': [{'tlemma': 'outdoors', 'tlem...   \n",
       "  1  {'noncore_args': [{'tlemma': 'outdoors', 'tlem...   \n",
       "3 0  {'noncore_args': [], 'core_args': [], 'blank_i...   \n",
       "  1  {'noncore_args': [{'tlemma': 'at their parents...   \n",
       "  2  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "  3  {'noncore_args': [], 'core_args': [], 'blank_i...   \n",
       "  4  {'noncore_args': [{'tlemma': 'at their parents...   \n",
       "4 0  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "  1  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "\n",
       "                              name        description  \n",
       "0 0                   change_voice  preserves_meaning  \n",
       "  1                   change_voice  preserves_meaning  \n",
       "  2         swap_core_with_context    changes_meaning  \n",
       "  3      swap_core_without_context    changes_meaning  \n",
       "  4          shorten_core_argument  preserves_meaning  \n",
       "  5          shorten_core_argument  preserves_meaning  \n",
       "  6                   change_tense  preserves_meaning  \n",
       "  7                   change_tense  preserves_meaning  \n",
       "  8  replace_core_with_subsequence    changes_meaning  \n",
       "1 0                   change_voice  preserves_meaning  \n",
       "  1                   change_voice  preserves_meaning  \n",
       "  2         swap_core_with_context    changes_meaning  \n",
       "  3      swap_core_without_context    changes_meaning  \n",
       "  4          shorten_core_argument  preserves_meaning  \n",
       "  5                   change_tense  preserves_meaning  \n",
       "  6                   change_tense  preserves_meaning  \n",
       "2 0                   change_voice  preserves_meaning  \n",
       "  1                   change_tense  preserves_meaning  \n",
       "3 0                   change_voice  preserves_meaning  \n",
       "  1                   change_voice  preserves_meaning  \n",
       "  2          shorten_core_argument  preserves_meaning  \n",
       "  3                   change_tense  preserves_meaning  \n",
       "  4                   change_tense  preserves_meaning  \n",
       "4 0                   change_voice  preserves_meaning  \n",
       "  1                   change_tense  preserves_meaning  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_as_dataframe(sentence_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a36d26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.steps.generate_from_prompts import GenerateFromPrompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e50ee808",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/akshitab/local/code/ai2-tailor/tailor/steps/generate_from_prompts.py\", line 138, in run\n",
      "    prompt_dict = parse_filled_prompt(\n",
      "  File \"/Users/akshitab/local/code/ai2-tailor/tailor/common/utils/head_prompt_utils.py\", line 2181, in parse_filled_prompt\n",
      "    raise BadGenerationError(f\"Bad generation: {prompt}\")\n",
      "tailor.common.utils.head_prompt_utils.BadGenerationError: Bad generation: Those who have a strong grip on -LRB- stout, but tame yuppie hat's horse ; those who are unable to raise tha hygienically en mass or go to school with their horses eh he is afraid. If someone gets caught in dread and tries to make hay and buy the horse back & fro / er? oh yes! 0 och p adolen\n"
     ]
    }
   ],
   "source": [
    "generations = GenerateFromPrompts().run(\n",
    "    processed_sentences=processed_sentences,\n",
    "    prompts=sentence_prompts,\n",
    "    spacy_model=spacy_model,\n",
    "    compute_perplexity=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "867717bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_no_header</th>\n",
       "      <th>sentence</th>\n",
       "      <th>meta</th>\n",
       "      <th>annotations</th>\n",
       "      <th>words</th>\n",
       "      <th>vidx</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>perplexities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>- [GOAL: his horse]'s [VERB: trained] [AGENT: ...</td>\n",
       "      <td>- his horse 's trained by a person | for . os .</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 29), mat...</td>\n",
       "      <td>[{'tag': 'GOAL', 'start': 1, 'end': 3, 'pred':...</td>\n",
       "      <td>[-, his, horse, 's, trained, by, a, person, |,...</td>\n",
       "      <td>4</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>preserves_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 60.997093200683594, 'pr_phrase': -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'PREDIOBOMO: FEIRUINE: BENESISTS BASE OF WALLI...</td>\n",
       "      <td>' FEIRUINE : BENESISTS BASE OF WALLINSIDE VALL...</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'TEMPORAL', 'start': 1, 'end': 8, 'pr...</td>\n",
       "      <td>[', FEIRUINE, :, BENESISTS, BASE, OF, WALLINSI...</td>\n",
       "      <td>-1</td>\n",
       "      <td>swap_core_with_context</td>\n",
       "      <td>changes_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 463.1181106567383, 'pr_phrase': 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>- [AGENT: a person], [VERB: training] [PATIENT...</td>\n",
       "      <td>- a person , training for competition</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, a, person, ,, training, for, competition]</td>\n",
       "      <td>4</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>preserves_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 5.577220916748047, 'pr_phrase': 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- [AGENT: a person]'s [VERB: training] [PATIEN...</td>\n",
       "      <td>- a person 's training for tte competition</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, a, person, 's, training, for, tte, competi...</td>\n",
       "      <td>4</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>preserves_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 23.869155883789062, 'pr_phrase': 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- [AGENT: a person], [VERB: training] [PATIENT...</td>\n",
       "      <td>- a person , training for competition</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, a, person, ,, training, for, competition]</td>\n",
       "      <td>4</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>preserves_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 5.577220916748047, 'pr_phrase': 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>- [AGENT: A person]'s [VERB: training] [PATIEN...</td>\n",
       "      <td>- A person 's training for a competition</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, A, person, 's, training, for, a, competition]</td>\n",
       "      <td>4</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>preserves_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 7.308444976806641, 'pr_phrase': 4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>- [AGENT: a person] [MODAL: will]'be [VERB: tr...</td>\n",
       "      <td>- a person will ' be training his his horse --...</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 27), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, a, person, will, ', be, training, his, his...</td>\n",
       "      <td>6</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>preserves_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 65.06066131591797, 'pr_phrase': 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[AGENT: a person]'s [VERB: training] [PATIENT;...</td>\n",
       "      <td>a person 's training for .. tr .</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...</td>\n",
       "      <td>[a, person, 's, training, for, .., tr, .]</td>\n",
       "      <td>3</td>\n",
       "      <td>replace_core_with_subsequence</td>\n",
       "      <td>changes_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 22.215484619140625, 'pr_phrase': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[AGENT: a person]'s [VERB: training] [PATIENT ...</td>\n",
       "      <td>a person 's training for sass</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...</td>\n",
       "      <td>[a, person, 's, training, for, sass]</td>\n",
       "      <td>3</td>\n",
       "      <td>replace_core_with_subsequence</td>\n",
       "      <td>changes_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 8.735004425048828, 'pr_phrase': 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[AGENT: a person] [VERB: trains] - [PATIENT; f...</td>\n",
       "      <td>a person trains - for , say .. :</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...</td>\n",
       "      <td>[a, person, trains, -, for, ,, say, .., :]</td>\n",
       "      <td>2</td>\n",
       "      <td>replace_core_with_subsequence</td>\n",
       "      <td>changes_meaning</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 27.191421508789062, 'pr_phrase': 2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    prompt_no_header  \\\n",
       "0  - [GOAL: his horse]'s [VERB: trained] [AGENT: ...   \n",
       "1  'PREDIOBOMO: FEIRUINE: BENESISTS BASE OF WALLI...   \n",
       "2  - [AGENT: a person], [VERB: training] [PATIENT...   \n",
       "3  - [AGENT: a person]'s [VERB: training] [PATIEN...   \n",
       "4  - [AGENT: a person], [VERB: training] [PATIENT...   \n",
       "5  - [AGENT: A person]'s [VERB: training] [PATIEN...   \n",
       "6  - [AGENT: a person] [MODAL: will]'be [VERB: tr...   \n",
       "7  [AGENT: a person]'s [VERB: training] [PATIENT;...   \n",
       "8  [AGENT: a person]'s [VERB: training] [PATIENT ...   \n",
       "9  [AGENT: a person] [VERB: trains] - [PATIENT; f...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0    - his horse 's trained by a person | for . os .   \n",
       "1  ' FEIRUINE : BENESISTS BASE OF WALLINSIDE VALL...   \n",
       "2              - a person , training for competition   \n",
       "3         - a person 's training for tte competition   \n",
       "4              - a person , training for competition   \n",
       "5           - A person 's training for a competition   \n",
       "6  - a person will ' be training his his horse --...   \n",
       "7                   a person 's training for .. tr .   \n",
       "8                      a person 's training for sass   \n",
       "9                   a person trains - for , say .. :   \n",
       "\n",
       "                                                meta  \\\n",
       "0  {'match': '<re.Match object; span=(0, 29), mat...   \n",
       "1  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "2  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "3  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "4  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "5  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "6  {'match': '<re.Match object; span=(0, 27), mat...   \n",
       "7  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "8  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "9  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  [{'tag': 'GOAL', 'start': 1, 'end': 3, 'pred':...   \n",
       "1  [{'tag': 'TEMPORAL', 'start': 1, 'end': 8, 'pr...   \n",
       "2  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "3  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "4  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "5  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "6  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "7  [{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...   \n",
       "8  [{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...   \n",
       "9  [{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...   \n",
       "\n",
       "                                               words  vidx  \\\n",
       "0  [-, his, horse, 's, trained, by, a, person, |,...     4   \n",
       "1  [', FEIRUINE, :, BENESISTS, BASE, OF, WALLINSI...    -1   \n",
       "2      [-, a, person, ,, training, for, competition]     4   \n",
       "3  [-, a, person, 's, training, for, tte, competi...     4   \n",
       "4      [-, a, person, ,, training, for, competition]     4   \n",
       "5  [-, A, person, 's, training, for, a, competition]     4   \n",
       "6  [-, a, person, will, ', be, training, his, his...     6   \n",
       "7          [a, person, 's, training, for, .., tr, .]     3   \n",
       "8               [a, person, 's, training, for, sass]     3   \n",
       "9         [a, person, trains, -, for, ,, say, .., :]     2   \n",
       "\n",
       "                            name        description is_valid  \\\n",
       "0                   change_voice  preserves_meaning     None   \n",
       "1         swap_core_with_context    changes_meaning     None   \n",
       "2          shorten_core_argument  preserves_meaning     None   \n",
       "3          shorten_core_argument  preserves_meaning     None   \n",
       "4          shorten_core_argument  preserves_meaning     None   \n",
       "5          shorten_core_argument  preserves_meaning     None   \n",
       "6                   change_tense  preserves_meaning     None   \n",
       "7  replace_core_with_subsequence    changes_meaning     None   \n",
       "8  replace_core_with_subsequence    changes_meaning     None   \n",
       "9  replace_core_with_subsequence    changes_meaning     None   \n",
       "\n",
       "                                        perplexities  \n",
       "0  {'pr_sent': 60.997093200683594, 'pr_phrase': -...  \n",
       "1  {'pr_sent': 463.1181106567383, 'pr_phrase': 14...  \n",
       "2  {'pr_sent': 5.577220916748047, 'pr_phrase': 7....  \n",
       "3  {'pr_sent': 23.869155883789062, 'pr_phrase': 7...  \n",
       "4  {'pr_sent': 5.577220916748047, 'pr_phrase': 7....  \n",
       "5  {'pr_sent': 7.308444976806641, 'pr_phrase': 4....  \n",
       "6  {'pr_sent': 65.06066131591797, 'pr_phrase': 7....  \n",
       "7  {'pr_sent': 22.215484619140625, 'pr_phrase': 2...  \n",
       "8  {'pr_sent': 8.735004425048828, 'pr_phrase': 2....  \n",
       "9  {'pr_sent': 27.191421508789062, 'pr_phrase': 2...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_as_dataframe(generations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbea79a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.tasks.nli.augment import AugmentNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b0b05894",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = AugmentNLI().run(dataset=data_dict, perturbed_field=key_to_perturb, generated_prompt_dicts=generations, max_augment_per_instance=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d535214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.steps.convert_dataset_to_dict import ConvertDictToDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c0acd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataset = ConvertDictToDataset().run(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3bed587f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "041ff70f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premise': ['A person on a horse jumps over a broken down airplane.',\n",
       "  'A person on a horse jumps over a broken down airplane.',\n",
       "  'A person on a horse jumps over a broken down airplane.',\n",
       "  'Children smiling and waving at camera',\n",
       "  'Children smiling and waving at camera'],\n",
       " 'hypothesis': [\"- his horse 's trained by a person | for . os .\",\n",
       "  \"an omelette 's ordered by a person\",\n",
       "  \"an omelette 's ordered person\",\n",
       "  '... they smile',\n",
       "  \"- they smiled ' at their parents\"],\n",
       " 'label': [1, 2, 2, 1, 1]}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034d6a83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
