{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d47e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07b24d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_as_dataframe(list_of_namedtuples):\n",
    "    return pd.DataFrame(list_of_namedtuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "981bbb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset snli (/Users/akshitab/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d3bf252737d421d9c544c371fe93b79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "snli = datasets.load_dataset(\"snli\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025cbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypotheses = snli[\"train\"][:5][\"hypothesis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa32ded2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A person is training his horse for a competition.',\n",
       " 'A person is at a diner, ordering an omelette.',\n",
       " 'A person is outdoors, on a horse.',\n",
       " 'They are smiling at their parents',\n",
       " 'There are children present']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58a5303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.steps.process_with_spacy import GetSpacyModel, ProcessWithSpacy\n",
    "from tailor.steps.get_srl_tags import GetSRLTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9f5e220",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_model = GetSpacyModel().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c32193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_hypotheses = ProcessWithSpacy().run(sentences=hypotheses, spacy_model=spacy_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79f207e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[A person is training his horse for a competition.,\n",
       " A person is at a diner, ordering an omelette.,\n",
       " A person is outdoors, on a horse.,\n",
       " They are smiling at their parents,\n",
       " There are children present]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56f5ddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 20:46:34,525 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
      "2022-02-02 20:46:34,533 - INFO - allennlp.models.archival - loading archive file /Users/akshitab/.cache/cached_path/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3\n",
      "2022-02-02 20:46:34,534 - INFO - allennlp.models.archival - extracting archive file /Users/akshitab/.cache/cached_path/b5f1db011cc85691a5fa2bf29e055a712261a2e5d74a74edd7da2fffc98d4ab8.4c4ac7e06ec3d85631bd26b839f90b5a375d3ceeb43e3c74f1cf4758dcee2bb3 to temp dir /var/folders/hj/vgtd6j153yq38z5xtrvrmpqr0000gn/T/tmppavw9tpi\n",
      "2022-02-02 20:46:38,128 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-02-02 20:46:38,129 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-02-02 20:46:38,130 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-02-02 20:46:38,130 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-02-02 20:46:38,131 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-02-02 20:46:38,132 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-02-02 20:46:38,132 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2022-02-02 20:47:04,831 - INFO - allennlp.common.params - dataset_reader.type = srl\n",
      "2022-02-02 20:47:04,832 - INFO - allennlp.common.params - dataset_reader.max_instances = None\n",
      "2022-02-02 20:47:04,832 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
      "2022-02-02 20:47:04,833 - INFO - allennlp.common.params - dataset_reader.manual_multiprocess_sharding = False\n",
      "2022-02-02 20:47:04,834 - INFO - allennlp.common.params - dataset_reader.token_indexers = None\n",
      "2022-02-02 20:47:04,835 - INFO - allennlp.common.params - dataset_reader.domain_identifier = None\n",
      "2022-02-02 20:47:04,835 - INFO - allennlp.common.params - dataset_reader.bert_model_name = bert-base-uncased\n",
      "2022-02-02 20:47:11,178 - INFO - allennlp.common.params - type = from_instances\n",
      "2022-02-02 20:47:11,179 - INFO - allennlp.data.vocabulary - Loading token dictionary from /var/folders/hj/vgtd6j153yq38z5xtrvrmpqr0000gn/T/tmppavw9tpi/vocabulary.\n",
      "2022-02-02 20:47:11,181 - INFO - allennlp.common.params - model.type = srl_bert\n",
      "2022-02-02 20:47:11,182 - INFO - allennlp.common.params - model.regularizer = None\n",
      "2022-02-02 20:47:11,183 - INFO - allennlp.common.params - model.ddp_accelerator = None\n",
      "2022-02-02 20:47:11,184 - INFO - allennlp.common.params - model.bert_model = bert-base-uncased\n",
      "2022-02-02 20:47:11,184 - INFO - allennlp.common.params - model.embedding_dropout = 0.1\n",
      "2022-02-02 20:47:11,185 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7fc43a69cb20>\n",
      "2022-02-02 20:47:11,185 - INFO - allennlp.common.params - model.label_smoothing = None\n",
      "2022-02-02 20:47:11,186 - INFO - allennlp.common.params - model.ignore_span_metric = False\n",
      "2022-02-02 20:47:11,187 - INFO - allennlp.common.params - model.srl_eval_path = /Users/akshitab/virtuals/tailor/lib/python3.8/site-packages/allennlp_models/structured_prediction/tools/srl-eval.pl\n",
      "2022-02-02 20:47:16,770 - INFO - allennlp.nn.initializers - Initializing parameters\n",
      "2022-02-02 20:47:16,772 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "2022-02-02 20:47:16,772 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.bias\n",
      "2022-02-02 20:47:16,773 - INFO - allennlp.nn.initializers -    bert_model.embeddings.LayerNorm.weight\n",
      "2022-02-02 20:47:16,773 - INFO - allennlp.nn.initializers -    bert_model.embeddings.position_embeddings.weight\n",
      "2022-02-02 20:47:16,774 - INFO - allennlp.nn.initializers -    bert_model.embeddings.token_type_embeddings.weight\n",
      "2022-02-02 20:47:16,775 - INFO - allennlp.nn.initializers -    bert_model.embeddings.word_embeddings.weight\n",
      "2022-02-02 20:47:16,776 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,776 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,777 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,777 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,778 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.bias\n",
      "2022-02-02 20:47:16,779 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.key.weight\n",
      "2022-02-02 20:47:16,779 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.bias\n",
      "2022-02-02 20:47:16,780 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.query.weight\n",
      "2022-02-02 20:47:16,781 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.bias\n",
      "2022-02-02 20:47:16,782 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.attention.self.value.weight\n",
      "2022-02-02 20:47:16,783 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,783 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,784 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,785 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,785 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.bias\n",
      "2022-02-02 20:47:16,786 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.0.output.dense.weight\n",
      "2022-02-02 20:47:16,787 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,787 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,788 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,788 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,789 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.bias\n",
      "2022-02-02 20:47:16,790 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.key.weight\n",
      "2022-02-02 20:47:16,791 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.bias\n",
      "2022-02-02 20:47:16,792 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.query.weight\n",
      "2022-02-02 20:47:16,793 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.bias\n",
      "2022-02-02 20:47:16,794 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.attention.self.value.weight\n",
      "2022-02-02 20:47:16,796 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,796 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,798 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,799 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,800 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.bias\n",
      "2022-02-02 20:47:16,801 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.1.output.dense.weight\n",
      "2022-02-02 20:47:16,802 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,803 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,804 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,805 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.output.dense.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 20:47:16,806 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.bias\n",
      "2022-02-02 20:47:16,806 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.key.weight\n",
      "2022-02-02 20:47:16,807 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.bias\n",
      "2022-02-02 20:47:16,807 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.query.weight\n",
      "2022-02-02 20:47:16,808 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.bias\n",
      "2022-02-02 20:47:16,809 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.attention.self.value.weight\n",
      "2022-02-02 20:47:16,809 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,810 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,811 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,812 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,813 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.bias\n",
      "2022-02-02 20:47:16,813 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.10.output.dense.weight\n",
      "2022-02-02 20:47:16,815 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,816 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,818 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,820 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,821 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.bias\n",
      "2022-02-02 20:47:16,822 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.key.weight\n",
      "2022-02-02 20:47:16,823 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.bias\n",
      "2022-02-02 20:47:16,824 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.query.weight\n",
      "2022-02-02 20:47:16,825 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.bias\n",
      "2022-02-02 20:47:16,826 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.attention.self.value.weight\n",
      "2022-02-02 20:47:16,827 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,827 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,828 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,828 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,829 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.bias\n",
      "2022-02-02 20:47:16,830 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.11.output.dense.weight\n",
      "2022-02-02 20:47:16,831 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,832 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,833 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,834 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,835 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.bias\n",
      "2022-02-02 20:47:16,836 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.key.weight\n",
      "2022-02-02 20:47:16,836 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.bias\n",
      "2022-02-02 20:47:16,837 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.query.weight\n",
      "2022-02-02 20:47:16,838 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.bias\n",
      "2022-02-02 20:47:16,838 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.attention.self.value.weight\n",
      "2022-02-02 20:47:16,839 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,840 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,840 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,841 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,842 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.bias\n",
      "2022-02-02 20:47:16,842 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.2.output.dense.weight\n",
      "2022-02-02 20:47:16,844 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,845 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,845 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,846 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,847 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.bias\n",
      "2022-02-02 20:47:16,848 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.key.weight\n",
      "2022-02-02 20:47:16,849 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.bias\n",
      "2022-02-02 20:47:16,850 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.query.weight\n",
      "2022-02-02 20:47:16,851 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.bias\n",
      "2022-02-02 20:47:16,852 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.attention.self.value.weight\n",
      "2022-02-02 20:47:16,853 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,854 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,854 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,855 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,855 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.bias\n",
      "2022-02-02 20:47:16,856 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.3.output.dense.weight\n",
      "2022-02-02 20:47:16,857 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,858 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,859 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,859 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,860 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.bias\n",
      "2022-02-02 20:47:16,861 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.key.weight\n",
      "2022-02-02 20:47:16,861 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.bias\n",
      "2022-02-02 20:47:16,862 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.query.weight\n",
      "2022-02-02 20:47:16,863 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.bias\n",
      "2022-02-02 20:47:16,863 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.attention.self.value.weight\n",
      "2022-02-02 20:47:16,865 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.bias\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 20:47:16,865 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,866 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,867 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,867 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.bias\n",
      "2022-02-02 20:47:16,868 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.4.output.dense.weight\n",
      "2022-02-02 20:47:16,869 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,869 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,870 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,872 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,873 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.bias\n",
      "2022-02-02 20:47:16,874 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.key.weight\n",
      "2022-02-02 20:47:16,875 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.bias\n",
      "2022-02-02 20:47:16,875 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.query.weight\n",
      "2022-02-02 20:47:16,876 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.bias\n",
      "2022-02-02 20:47:16,877 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.attention.self.value.weight\n",
      "2022-02-02 20:47:16,878 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,879 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,879 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,880 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,881 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.bias\n",
      "2022-02-02 20:47:16,881 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.5.output.dense.weight\n",
      "2022-02-02 20:47:16,882 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,883 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,884 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,884 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,886 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.bias\n",
      "2022-02-02 20:47:16,886 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.key.weight\n",
      "2022-02-02 20:47:16,887 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.bias\n",
      "2022-02-02 20:47:16,888 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.query.weight\n",
      "2022-02-02 20:47:16,889 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.bias\n",
      "2022-02-02 20:47:16,890 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.attention.self.value.weight\n",
      "2022-02-02 20:47:16,891 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,892 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,893 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,894 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,895 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.bias\n",
      "2022-02-02 20:47:16,896 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.6.output.dense.weight\n",
      "2022-02-02 20:47:16,896 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,897 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,898 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,899 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,901 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.bias\n",
      "2022-02-02 20:47:16,902 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.key.weight\n",
      "2022-02-02 20:47:16,902 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.bias\n",
      "2022-02-02 20:47:16,903 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.query.weight\n",
      "2022-02-02 20:47:16,904 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.bias\n",
      "2022-02-02 20:47:16,904 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.attention.self.value.weight\n",
      "2022-02-02 20:47:16,905 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,905 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,906 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,906 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,907 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.bias\n",
      "2022-02-02 20:47:16,907 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.7.output.dense.weight\n",
      "2022-02-02 20:47:16,908 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,909 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,909 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,910 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,910 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.bias\n",
      "2022-02-02 20:47:16,911 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.key.weight\n",
      "2022-02-02 20:47:16,911 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.bias\n",
      "2022-02-02 20:47:16,912 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.query.weight\n",
      "2022-02-02 20:47:16,912 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.bias\n",
      "2022-02-02 20:47:16,914 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.attention.self.value.weight\n",
      "2022-02-02 20:47:16,916 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,917 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,918 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,919 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,919 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.bias\n",
      "2022-02-02 20:47:16,920 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.8.output.dense.weight\n",
      "2022-02-02 20:47:16,920 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,921 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 20:47:16,922 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "2022-02-02 20:47:16,922 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "2022-02-02 20:47:16,923 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.bias\n",
      "2022-02-02 20:47:16,924 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.key.weight\n",
      "2022-02-02 20:47:16,924 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.bias\n",
      "2022-02-02 20:47:16,925 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.query.weight\n",
      "2022-02-02 20:47:16,926 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.bias\n",
      "2022-02-02 20:47:16,927 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.attention.self.value.weight\n",
      "2022-02-02 20:47:16,927 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "2022-02-02 20:47:16,928 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "2022-02-02 20:47:16,929 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2022-02-02 20:47:16,930 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2022-02-02 20:47:16,931 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.bias\n",
      "2022-02-02 20:47:16,932 - INFO - allennlp.nn.initializers -    bert_model.encoder.layer.9.output.dense.weight\n",
      "2022-02-02 20:47:16,932 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.bias\n",
      "2022-02-02 20:47:16,933 - INFO - allennlp.nn.initializers -    bert_model.pooler.dense.weight\n",
      "2022-02-02 20:47:16,934 - INFO - allennlp.nn.initializers -    tag_projection_layer.bias\n",
      "2022-02-02 20:47:16,935 - INFO - allennlp.nn.initializers -    tag_projection_layer.weight\n",
      "2022-02-02 20:47:17,378 - INFO - allennlp.models.archival - removing temporary unarchived model dir at /var/folders/hj/vgtd6j153yq38z5xtrvrmpqr0000gn/T/tmppavw9tpi\n"
     ]
    }
   ],
   "source": [
    "processed_hypotheses = GetSRLTags().run(spacy_outputs=spacy_hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ccc28560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>spacy_doc</th>\n",
       "      <th>verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person is training his horse for a competiti...</td>\n",
       "      <td>(A, person, is, training, his, horse, for, a, ...</td>\n",
       "      <td>[{'verb': 'is', 'description': 'A person [V: i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person is at a diner , ordering an omelette .</td>\n",
       "      <td>(A, person, is, at, a, diner, ,, ordering, an,...</td>\n",
       "      <td>[{'verb': 'is', 'description': '[ARG1: A perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A person is outdoors , on a horse .</td>\n",
       "      <td>(A, person, is, outdoors, ,, on, a, horse, .)</td>\n",
       "      <td>[{'verb': 'is', 'description': '[ARG1: A perso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They are smiling at their parents</td>\n",
       "      <td>(They, are, smiling, at, their, parents)</td>\n",
       "      <td>[{'verb': 'are', 'description': 'They [V: are]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are children present</td>\n",
       "      <td>(There, are, children, present)</td>\n",
       "      <td>[{'verb': 'are', 'description': 'There [V: are...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  A person is training his horse for a competiti...   \n",
       "1    A person is at a diner , ordering an omelette .   \n",
       "2                A person is outdoors , on a horse .   \n",
       "3                  They are smiling at their parents   \n",
       "4                         There are children present   \n",
       "\n",
       "                                           spacy_doc  \\\n",
       "0  (A, person, is, training, his, horse, for, a, ...   \n",
       "1  (A, person, is, at, a, diner, ,, ordering, an,...   \n",
       "2      (A, person, is, outdoors, ,, on, a, horse, .)   \n",
       "3           (They, are, smiling, at, their, parents)   \n",
       "4                    (There, are, children, present)   \n",
       "\n",
       "                                               verbs  \n",
       "0  [{'verb': 'is', 'description': 'A person [V: i...  \n",
       "1  [{'verb': 'is', 'description': '[ARG1: A perso...  \n",
       "2  [{'verb': 'is', 'description': '[ARG1: A perso...  \n",
       "3  [{'verb': 'are', 'description': 'They [V: are]...  \n",
       "4  [{'verb': 'are', 'description': 'There [V: are...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_as_dataframe(processed_hypotheses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fb55120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.common.perturb_function import ChangeVoice, SwapCoreWithContext, SwapCoreWithoutContext, ShortenCoreArgument, ChangeTense\n",
    "from tailor.steps.perturb_prompt import PerturbPromptWithString\n",
    "from tailor.steps.combine_all_prompts import CombineAllPrompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da6df0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "step = PerturbPromptWithString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b15d0d05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning. Perturbed prompt is same as base prompt. This should not be happening.\n"
     ]
    }
   ],
   "source": [
    "hypotheses_prompts = []\n",
    "for perturb_fn in [ChangeVoice, SwapCoreWithContext, SwapCoreWithoutContext, ShortenCoreArgument, ChangeTense]:\n",
    "    perturbations = PerturbPromptWithString().run(processed_sentences=processed_hypotheses, perturb_str_func=perturb_fn())\n",
    "    hypotheses_prompts.append(perturbations)\n",
    "    \n",
    "hypotheses_prompts = CombineAllPrompts().run(hypotheses_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "440d051d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>answer</th>\n",
       "      <th>meta</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[VERB+passive+present: be]  &lt;extra_id_0&gt;</td>\n",
       "      <td>A person [VERB: is] training his horse for a c...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [], 'blank_i...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[VERB+passive+present: train | AGENT+complete:...</td>\n",
       "      <td>[AGENT: A person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'his horse', 'tle...</td>\n",
       "      <td>change_voice</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[VERB+active+present: train | AGENT+complete: ...</td>\n",
       "      <td>[PATIENT: A person] is [VERB: training] [GOAL:...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'his horse', 'tle...</td>\n",
       "      <td>swap_core_with_context</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[VERB+active+present: train | AGENT+complete: ...</td>\n",
       "      <td>[PATIENT: A person] is [VERB: training] [GOAL:...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'his horse', 'tle...</td>\n",
       "      <td>swap_core_without_context</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[VERB+active+present: train | AGENT+complete: ...</td>\n",
       "      <td>[AGENT: A person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[VERB+active+present: train | AGENT+complete: ...</td>\n",
       "      <td>[AGENT: A person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [{'tlemma': ...</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[VERB+active+past: be] A person &lt;extra_id_0&gt; &lt;...</td>\n",
       "      <td>A person [VERB: is] training his horse for a c...</td>\n",
       "      <td>{'noncore_args': [], 'core_args': [], 'blank_i...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[VERB+active+past: train | AGENT+complete: a p...</td>\n",
       "      <td>[AGENT: A person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>{'noncore_args': [{'tlemma': 'his horse', 'tle...</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0           [VERB+passive+present: be]  <extra_id_0>   \n",
       "1  [VERB+passive+present: train | AGENT+complete:...   \n",
       "2  [VERB+active+present: train | AGENT+complete: ...   \n",
       "3  [VERB+active+present: train | AGENT+complete: ...   \n",
       "4  [VERB+active+present: train | AGENT+complete: ...   \n",
       "5  [VERB+active+present: train | AGENT+complete: ...   \n",
       "6  [VERB+active+past: be] A person <extra_id_0> <...   \n",
       "7  [VERB+active+past: train | AGENT+complete: a p...   \n",
       "\n",
       "                                              answer  \\\n",
       "0  A person [VERB: is] training his horse for a c...   \n",
       "1  [AGENT: A person] is [VERB: training] [GOAL: h...   \n",
       "2  [PATIENT: A person] is [VERB: training] [GOAL:...   \n",
       "3  [PATIENT: A person] is [VERB: training] [GOAL:...   \n",
       "4  [AGENT: A person] is [VERB: training] [GOAL: h...   \n",
       "5  [AGENT: A person] is [VERB: training] [GOAL: h...   \n",
       "6  A person [VERB: is] training his horse for a c...   \n",
       "7  [AGENT: A person] is [VERB: training] [GOAL: h...   \n",
       "\n",
       "                                                meta  \\\n",
       "0  {'noncore_args': [], 'core_args': [], 'blank_i...   \n",
       "1  {'noncore_args': [{'tlemma': 'his horse', 'tle...   \n",
       "2  {'noncore_args': [{'tlemma': 'his horse', 'tle...   \n",
       "3  {'noncore_args': [{'tlemma': 'his horse', 'tle...   \n",
       "4  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "5  {'noncore_args': [], 'core_args': [{'tlemma': ...   \n",
       "6  {'noncore_args': [], 'core_args': [], 'blank_i...   \n",
       "7  {'noncore_args': [{'tlemma': 'his horse', 'tle...   \n",
       "\n",
       "                        name description  \n",
       "0               change_voice        None  \n",
       "1               change_voice        None  \n",
       "2     swap_core_with_context        None  \n",
       "3  swap_core_without_context        None  \n",
       "4      shorten_core_argument        None  \n",
       "5      shorten_core_argument        None  \n",
       "6               change_tense        None  \n",
       "7               change_tense        None  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_as_dataframe(hypotheses_prompts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a36d26cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.steps.generate_from_prompts import GenerateFromPrompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e50ee808",
   "metadata": {},
   "outputs": [],
   "source": [
    "generations = GenerateFromPrompts().run(\n",
    "    processed_sentences=processed_hypotheses,\n",
    "    prompts=hypotheses_prompts,\n",
    "    spacy_model=spacy_model,\n",
    "    compute_perplexity=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "867717bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_no_header</th>\n",
       "      <th>sentence</th>\n",
       "      <th>meta</th>\n",
       "      <th>annotations</th>\n",
       "      <th>words</th>\n",
       "      <th>vidx</th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>is_valid</th>\n",
       "      <th>perplexities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[AGENT: for a competition] is [VERB: training]...</td>\n",
       "      <td>for a competition is training - his horse dh</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 0, 'end': 3, 'pred'...</td>\n",
       "      <td>[for, a, competition, is, training, -, his, ho...</td>\n",
       "      <td>4</td>\n",
       "      <td>swap_core_with_context</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 34.192474365234375, 'pr_phrase': 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>, [AGENT: for a competition] is... -LRB- to wi...</td>\n",
       "      <td>, for a competition is ... - to win / train hi...</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 4, 'pred'...</td>\n",
       "      <td>[,, for, a, competition, is, ..., -, to, win, ...</td>\n",
       "      <td>10</td>\n",
       "      <td>swap_core_with_context</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 53.756065368652344, 'pr_phrase': 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a horse] t [VERB: train] [GOAL: his horse/AGEN...</td>\n",
       "      <td>a horse ] t train his horse / AGENT : for s co...</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'VERB', 'start': 4, 'end': 5, 'pred':...</td>\n",
       "      <td>[a, horse, ], t, train, his, horse, /, AGENT, ...</td>\n",
       "      <td>4</td>\n",
       "      <td>swap_core_without_context</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 112.19617462158203, 'pr_phrase': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- [AGENT: a person] [VERB: trains], [PATIENT; ...</td>\n",
       "      <td>- a person trains , for competition</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, a, person, trains, ,, for, competition]</td>\n",
       "      <td>3</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 9.296089172363281, 'pr_phrase': 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[AGENT: a person] [VERB: trains] - [PATIENT; f...</td>\n",
       "      <td>a person trains - for e-</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...</td>\n",
       "      <td>[a, person, trains, -, for, e-]</td>\n",
       "      <td>2</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 12.7371826171875, 'pr_phrase': 2.3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>- [AGENT: a person] [VERB: trains]'[PATIENT; f...</td>\n",
       "      <td>- a person trains ' for competition</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, a, person, trains, ', for, competition]</td>\n",
       "      <td>3</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 11.641292572021484, 'pr_phrase': 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>- [AGENT: A person] [VERB: trains] a [PATIENT;...</td>\n",
       "      <td>- A person trains a for competition ''</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 28), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, A, person, trains, a, for, competition, '']</td>\n",
       "      <td>3</td>\n",
       "      <td>shorten_core_argument</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 17.736839294433594, 'pr_phrase': 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[AGENT: a person] is [VERB: training] [GOAL: h...</td>\n",
       "      <td>a person is training his horse - for refueling</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 25), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...</td>\n",
       "      <td>[a, person, is, training, his, horse, -, for, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 18.287376403808594, 'pr_phrase': 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>- [AGENT: a person] is [VERB: training] [GOAL:...</td>\n",
       "      <td>- a person is training his horse ' for refueli...</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 25), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, a, person, is, training, his, horse, ', fo...</td>\n",
       "      <td>4</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 40.43498992919922, 'pr_phrase': 7....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>- [AGENT: a person] is [VERB: training] [GOAL:...</td>\n",
       "      <td>- a person is training his horse , for ' eh .</td>\n",
       "      <td>{'match': '&lt;re.Match object; span=(0, 25), mat...</td>\n",
       "      <td>[{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...</td>\n",
       "      <td>[-, a, person, is, training, his, horse, ,, fo...</td>\n",
       "      <td>4</td>\n",
       "      <td>change_tense</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'pr_sent': 34.21985626220703, 'pr_phrase': 7....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    prompt_no_header  \\\n",
       "0  [AGENT: for a competition] is [VERB: training]...   \n",
       "1  , [AGENT: for a competition] is... -LRB- to wi...   \n",
       "2  a horse] t [VERB: train] [GOAL: his horse/AGEN...   \n",
       "3  - [AGENT: a person] [VERB: trains], [PATIENT; ...   \n",
       "4  [AGENT: a person] [VERB: trains] - [PATIENT; f...   \n",
       "5  - [AGENT: a person] [VERB: trains]'[PATIENT; f...   \n",
       "6  - [AGENT: A person] [VERB: trains] a [PATIENT;...   \n",
       "7  [AGENT: a person] is [VERB: training] [GOAL: h...   \n",
       "8  - [AGENT: a person] is [VERB: training] [GOAL:...   \n",
       "9  - [AGENT: a person] is [VERB: training] [GOAL:...   \n",
       "\n",
       "                                            sentence  \\\n",
       "0       for a competition is training - his horse dh   \n",
       "1  , for a competition is ... - to win / train hi...   \n",
       "2  a horse ] t train his horse / AGENT : for s co...   \n",
       "3                - a person trains , for competition   \n",
       "4                           a person trains - for e-   \n",
       "5                - a person trains ' for competition   \n",
       "6             - A person trains a for competition ''   \n",
       "7     a person is training his horse - for refueling   \n",
       "8  - a person is training his horse ' for refueli...   \n",
       "9      - a person is training his horse , for ' eh .   \n",
       "\n",
       "                                                meta  \\\n",
       "0  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "1  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "2  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "3  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "4  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "5  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "6  {'match': '<re.Match object; span=(0, 28), mat...   \n",
       "7  {'match': '<re.Match object; span=(0, 25), mat...   \n",
       "8  {'match': '<re.Match object; span=(0, 25), mat...   \n",
       "9  {'match': '<re.Match object; span=(0, 25), mat...   \n",
       "\n",
       "                                         annotations  \\\n",
       "0  [{'tag': 'AGENT', 'start': 0, 'end': 3, 'pred'...   \n",
       "1  [{'tag': 'AGENT', 'start': 1, 'end': 4, 'pred'...   \n",
       "2  [{'tag': 'VERB', 'start': 4, 'end': 5, 'pred':...   \n",
       "3  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "4  [{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...   \n",
       "5  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "6  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "7  [{'tag': 'AGENT', 'start': 0, 'end': 2, 'pred'...   \n",
       "8  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "9  [{'tag': 'AGENT', 'start': 1, 'end': 3, 'pred'...   \n",
       "\n",
       "                                               words  vidx  \\\n",
       "0  [for, a, competition, is, training, -, his, ho...     4   \n",
       "1  [,, for, a, competition, is, ..., -, to, win, ...    10   \n",
       "2  [a, horse, ], t, train, his, horse, /, AGENT, ...     4   \n",
       "3        [-, a, person, trains, ,, for, competition]     3   \n",
       "4                    [a, person, trains, -, for, e-]     2   \n",
       "5        [-, a, person, trains, ', for, competition]     3   \n",
       "6    [-, A, person, trains, a, for, competition, '']     3   \n",
       "7  [a, person, is, training, his, horse, -, for, ...     3   \n",
       "8  [-, a, person, is, training, his, horse, ', fo...     4   \n",
       "9  [-, a, person, is, training, his, horse, ,, fo...     4   \n",
       "\n",
       "                        name description is_valid  \\\n",
       "0     swap_core_with_context        None     None   \n",
       "1     swap_core_with_context        None     None   \n",
       "2  swap_core_without_context        None     None   \n",
       "3      shorten_core_argument        None     None   \n",
       "4      shorten_core_argument        None     None   \n",
       "5      shorten_core_argument        None     None   \n",
       "6      shorten_core_argument        None     None   \n",
       "7               change_tense        None     None   \n",
       "8               change_tense        None     None   \n",
       "9               change_tense        None     None   \n",
       "\n",
       "                                        perplexities  \n",
       "0  {'pr_sent': 34.192474365234375, 'pr_phrase': 5...  \n",
       "1  {'pr_sent': 53.756065368652344, 'pr_phrase': 6...  \n",
       "2  {'pr_sent': 112.19617462158203, 'pr_phrase': 1...  \n",
       "3  {'pr_sent': 9.296089172363281, 'pr_phrase': 7....  \n",
       "4  {'pr_sent': 12.7371826171875, 'pr_phrase': 2.3...  \n",
       "5  {'pr_sent': 11.641292572021484, 'pr_phrase': 7...  \n",
       "6  {'pr_sent': 17.736839294433594, 'pr_phrase': 4...  \n",
       "7  {'pr_sent': 18.287376403808594, 'pr_phrase': 2...  \n",
       "8  {'pr_sent': 40.43498992919922, 'pr_phrase': 7....  \n",
       "9  {'pr_sent': 34.21985626220703, 'pr_phrase': 7....  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_as_dataframe(generations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ef2ff40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tailor.steps.validate_generations import ValidateGenerations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8bf5dab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = ValidateGenerations().run(generations, perplex_thresh=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dca7087f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['- a person trains , for competition',\n",
       "  'a person trains - for e-',\n",
       "  \"- a person trains ' for competition\",\n",
       "  \"- A person trains a for competition ''\",\n",
       "  'a person is training his horse - for refueling'],\n",
       " [],\n",
       " [],\n",
       " [\"they 're smiling\", '- they are smiling , at their parents'],\n",
       " []]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b05894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
